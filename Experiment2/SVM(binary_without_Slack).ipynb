{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IcmgFMfx70LB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cvxopt as copt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RLj83D7E8qd3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLGPEzGJ76MU",
        "outputId": "fd99ff55-eeb5-4ecf-92dd-afe141e1ee2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14000, 11)\n"
          ]
        }
      ],
      "source": [
        "#Data Loading and Pre-Processing\n",
        "data = np.loadtxt('/content/drive/MyDrive/PRNN/Assignment_2/binary_class/multi_class_classification_data_group_5_train.txt', delimiter='\\t',skiprows=1)\n",
        "print(data.shape)\n",
        "\n",
        "train_ratio,test_ratio = 0.7,0.3\n",
        "np.random.shuffle(data)\n",
        "\n",
        "num_samples = len(data)\n",
        "num_train,num_test = int(train_ratio * num_samples),int(test_ratio * num_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvJfw0r2-Zh_"
      },
      "source": [
        "Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBbC05Gv76Ss",
        "outputId": "6f56c2ee-5cf1-498d-f333-9c8b9bf7b9cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 11200\n",
            "Test set size: 2800\n"
          ]
        }
      ],
      "source": [
        "#Data Splitting\n",
        "train_data,test_data = data[:num_train],data[num_train:]\n",
        "\n",
        "print(\"Training set size:\", len(train_data))\n",
        "print(\"Test set size:\", len(test_data))\n",
        "\n",
        "X_train = train_data[:, :-1]  # Features\n",
        "y_train = train_data[:, -1]   # Labels\n",
        "X_test = test_data[:, :-1]  # Features\n",
        "y_test = test_data[:, -1]   # Labels\n",
        "float_array = np.array(y_test)\n",
        "y_test = float_array.astype(int)\n",
        "num_classes = 2\n",
        "\n",
        "y_train = np.array(y_train * 2 - 1)\n",
        "y_test = np.array(y_test * 2 - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z68onuix-fzb"
      },
      "source": [
        "Define Kernels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpoLaFzv76Yl"
      },
      "outputs": [],
      "source": [
        "def linear_kernel(X1, X2):\n",
        "    return np.dot(X1, X2.T)\n",
        "\n",
        "def polynomial_kernel(X1, X2, degree=3):\n",
        "    return (np.dot(X1, X2.T) + 1) ** degree\n",
        "\n",
        "def rbf_kernel(X1, X2, gamma=1.0):\n",
        "    n1 = np.shape(X1)[0]\n",
        "    n2 = np.shape(X2)[0]\n",
        "    K = np.zeros((n1, n2))\n",
        "    for i in range(n1):\n",
        "        for j in range(n2):\n",
        "            K[i,j] = np.exp(-gamma * np.linalg.norm(X1[i] - X2[j])**2)\n",
        "    return K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwXm2d30-nB0"
      },
      "source": [
        "Define Optimization Function (without slack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exvRyD4276et"
      },
      "outputs": [],
      "source": [
        "def optimize_dual(X, y, kernel):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Compute the Gram matrix\n",
        "    K = kernel(X, X)\n",
        "\n",
        "    # Define the quadratic and linear terms of the QP problem\n",
        "    P = copt.matrix(np.outer(y, y) * K)\n",
        "    q = copt.matrix(-np.ones(n_samples))\n",
        "    G = copt.matrix(-np.eye(n_samples))  # No slack variables\n",
        "    h = copt.matrix(np.zeros(n_samples)) # No slack variables\n",
        "    A = copt.matrix(y.astype(float), (1, n_samples))\n",
        "    b = copt.matrix(0.0)\n",
        "\n",
        "    # Solve the QP problem\n",
        "    solution = copt.solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "    # Extract lagrange multipliers\n",
        "    alpha = np.array(solution['x'])\n",
        "    return alpha\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfO5CxZq-1fH"
      },
      "source": [
        "Train Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U94TwL-g76k7"
      },
      "outputs": [],
      "source": [
        "def train_svm(X_train, y_train, kernel):\n",
        "    alpha = optimize_dual(X_train, y_train, kernel)\n",
        "\n",
        "    # Compute support vectors\n",
        "    sv_idx = alpha > 1e-5  # Select support vectors with non-zero lagrange multipliers\n",
        "    sv_idx = sv_idx.flatten()\n",
        "    support_vectors = X_train[sv_idx]\n",
        "    support_vector_labels = y_train[sv_idx]\n",
        "    alpha_sv = alpha[sv_idx]\n",
        "\n",
        "    # Compute bias term\n",
        "    kernel_matrix = kernel(support_vectors, support_vectors)\n",
        "    alpha_sv = alpha_sv.reshape(-1,)\n",
        "    product = (support_vector_labels * alpha_sv)\n",
        "    decision_values = np.dot(kernel_matrix, product)\n",
        "    bias = np.mean(support_vector_labels - decision_values)\n",
        "    return support_vectors, support_vector_labels, alpha_sv, bias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBo-fCCx_uxC"
      },
      "source": [
        "Predict Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZbiEf5176rd"
      },
      "outputs": [],
      "source": [
        "def predict_svm(X_test, support_vectors, support_vector_labels, alpha_sv, bias, kernel):\n",
        "    decision_function = np.dot(kernel(X_test, support_vectors), (support_vector_labels * alpha_sv)) + bias\n",
        "    return np.sign(decision_function)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49xtdPFM_11i"
      },
      "source": [
        "Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwKf9QuI_4Hj"
      },
      "outputs": [],
      "source": [
        "def grid_search(X_train, y_train, X_test, y_test):\n",
        "    best_accuracy = -1<<31  #minimum value in 32-bit signed integer\n",
        "    best_kernel = None\n",
        "\n",
        "    # Define kernels to search\n",
        "    # kernels = [linear_kernel, polynomial_kernel, rbf_kernel]\n",
        "    kernels = [rbf_kernel]\n",
        "    for kernel in kernels:\n",
        "        # Train SVM model\n",
        "        support_vectors, support_vector_labels, alpha_sv, bias = train_svm(X_train, y_train, kernel)\n",
        "\n",
        "        # Predict using trained model\n",
        "        y_pred = predict_svm(X_test, support_vectors, support_vector_labels, alpha_sv, bias, kernel)\n",
        "\n",
        "        # Evaluate accuracy\n",
        "        accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "        # Check if this model is the best so far\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            if kernel == linear_kernel:\n",
        "                best_kernel = 'linear'\n",
        "            elif kernel == polynomial_kernel:\n",
        "                best_kernel = 'polynomial'\n",
        "            else:\n",
        "                best_kernel = 'rbf'\n",
        "\n",
        "    return {'kernel': best_kernel, 'accuracy': best_accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP1MDkphAELd"
      },
      "source": [
        "Perform Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXFm7E1B_6DJ",
        "outputId": "0e9874af-6905-40a5-fce2-33cad25f8b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -3.5263e+03 -1.3631e+04  5e+04  1e+02  3e+00\n",
            " 1: -5.6272e+03 -2.1105e+04  3e+04  7e+01  1e+00\n",
            " 2: -5.8875e+03 -1.8169e+04  2e+04  3e+01  7e-01\n",
            " 3: -6.1747e+03 -1.1186e+04  5e+03  3e+00  5e-02\n",
            " 4: -6.8821e+03 -8.1603e+03  1e+03  5e-01  1e-02\n",
            " 5: -7.0627e+03 -7.3655e+03  3e+02  8e-02  2e-03\n",
            " 6: -7.1129e+03 -7.1607e+03  5e+01  8e-03  2e-04\n",
            " 7: -7.1227e+03 -7.1272e+03  5e+00  6e-04  1e-05\n",
            " 8: -7.1238e+03 -7.1240e+03  2e-01  2e-05  3e-07\n",
            " 9: -7.1239e+03 -7.1239e+03  6e-03  3e-07  6e-09\n",
            "10: -7.1239e+03 -7.1239e+03  2e-04  4e-09  8e-11\n",
            "Optimal solution found.\n",
            "Best Kernel: rbf\n",
            "Best Accuracy: 0.7364285714285714\n"
          ]
        }
      ],
      "source": [
        "best_model = grid_search(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Print best hyperparameters and performance metrics\n",
        "print(\"Best Kernel:\", best_model['kernel'])\n",
        "print(\"Best Accuracy:\", best_model['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}