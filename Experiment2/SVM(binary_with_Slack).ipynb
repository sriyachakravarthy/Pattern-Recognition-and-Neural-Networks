{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5dJBQG5viDeK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cvxopt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3EM_U0EjMEv",
        "outputId": "64f10539-107c-452b-f0bb-0debb74811f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (1.3.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cvxopt as copt"
      ],
      "metadata": {
        "id": "LWwoi3EhjH8h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt('/content/drive/MyDrive/PRNN/Assignment_2/binary_class/multi_class_classification_data_group_5_train.txt', delimiter='\\t',skiprows=1)\n",
        "print(data.shape)\n",
        "\n",
        "train_ratio,test_ratio = 0.7,0.3\n",
        "np.random.shuffle(data)\n",
        "\n",
        "num_samples = len(data)\n",
        "num_train,num_test = int(train_ratio * num_samples),int(test_ratio * num_samples)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mU6NZvatRimW",
        "outputId": "33266b34-461d-44d1-f417-76d9d7b2c2a5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14000, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data Splitting\n",
        "train_data,test_data = data[:num_train],data[num_train:]\n",
        "\n",
        "print(\"Training set size:\", len(train_data))\n",
        "print(\"Test set size:\", len(test_data))\n",
        "\n",
        "X_train = train_data[:, :-1]  # Features\n",
        "y_train = train_data[:, -1]   # Labels\n",
        "X_test = test_data[:, :-1]  # Features\n",
        "y_test = test_data[:, -1]   # Labels\n",
        "float_array = np.array(y_test)\n",
        "y_test = float_array.astype(int)\n",
        "num_classes = 2\n",
        "\n",
        "y_train,y_test = np.array(y_train * 2 - 1),np.array(y_test * 2 - 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioUGzx-FRi64",
        "outputId": "e7278564-3a6d-49a8-873b-bc7930612e57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 9800\n",
            "Test set size: 4200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Kernels"
      ],
      "metadata": {
        "id": "DHkuyEp4SMNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linear_kernel(X1, X2): #No additional Hyperparameter\n",
        "    return np.dot(X1, X2.T)\n",
        "\n",
        "\n",
        "    # if X1.ndim != X2.ndim:\n",
        "    #   X1 = np.expand_dims(X1, axis=1)\n",
        "    #   X2 = np.expand_dims(X2, axis=1)\n",
        "    # return np.exp(-gamma * np.linalg.norm(X1 - X2) ** 2)"
      ],
      "metadata": {
        "id": "Y9vXjIP8RjHR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def polynomial_kernel(X1, X2, degree=3): #Hyperparameter = degree\n",
        "    return (np.dot(X1, X2.T) + 1) ** degree"
      ],
      "metadata": {
        "id": "otd6bpNln3Vl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rbf_kernel(X1, X2, gamma=1.0): #HyperParameter = gamma\n",
        "    n1 = np.shape(X1)[0]\n",
        "    n2 = np.shape(X2)[0]\n",
        "    K = np.zeros((n1, n2))\n",
        "    for i in range(n1):\n",
        "        for j in range(n2):\n",
        "            K[i,j] = np.exp(-gamma * np.linalg.norm(X1[i] - X2[j])**2)\n",
        "    return K"
      ],
      "metadata": {
        "id": "XNUCfbnpn3nC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Optimization Function  (With Slack)"
      ],
      "metadata": {
        "id": "WG-qbjQHjAUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_dual(X, y, kernel, C):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # Compute the Gram matrix\n",
        "    K = kernel(X, X)\n",
        "\n",
        "    # Define the quadratic and linear terms of the QP problem\n",
        "    P = copt.matrix(np.outer(y, y) * K)\n",
        "    q = copt.matrix(-np.ones(n_samples))\n",
        "    G = copt.matrix(np.vstack((-np.eye(n_samples), np.eye(n_samples))))\n",
        "    h = copt.matrix(np.hstack((np.zeros(n_samples), np.ones(n_samples) * C)))\n",
        "    A = copt.matrix(y.astype(float), (1, n_samples))\n",
        "    b = copt.matrix(0.0)\n",
        "    # Solve the QP problem\n",
        "    soln = copt.solvers.qp(P, q, G, h, A, b)\n",
        "\n",
        "    # Extract lagrange multipliers\n",
        "    a = np.array(soln['x'])\n",
        "    print(a )\n",
        "    return a"
      ],
      "metadata": {
        "id": "uX6kMavKUAHx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Function"
      ],
      "metadata": {
        "id": "fK-8ci29kDYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_svm(X_train, y_train, kernel, C):\n",
        "    alpha = optimize_dual(X_train, y_train, kernel, C)\n",
        "\n",
        "    # Compute support vectors\n",
        "    sv_idx = alpha > 0\n",
        "    sv_idx = sv_idx.flatten()\n",
        "    print(sv_idx)\n",
        "    support_vectors = X_train[sv_idx]\n",
        "    support_vector_labels = y_train[sv_idx]\n",
        "    alpha_sv = alpha[sv_idx]\n",
        "    # Compute kernel matrix only for support vectors and training samples\n",
        "    kernel_matrix = kernel(support_vectors, support_vectors)\n",
        "    alpha_sv = alpha_sv.reshape(-1,)\n",
        "    # Compute bias term\n",
        "    product = (support_vector_labels * alpha_sv)\n",
        "    decision_values = np.dot(kernel_matrix, product)\n",
        "    bias = np.mean(support_vector_labels - decision_values)\n",
        "    return support_vectors, support_vector_labels, alpha_sv, bias\n"
      ],
      "metadata": {
        "id": "Uf7eXRNIUAN5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict Function"
      ],
      "metadata": {
        "id": "vJvp19lpkkF2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_svm(X_test, support_vectors, support_vector_labels, alpha_sv, bias, kernel):\n",
        "    print(bias)\n",
        "    decision_function = np.dot(kernel(X_test, support_vectors), (support_vector_labels * alpha_sv)) + bias\n",
        "    print(\"decision_function\",decision_function)\n",
        "    print(np.sign(decision_function))\n",
        "    return np.sign(decision_function)\n"
      ],
      "metadata": {
        "id": "xbk5GifnUATb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search"
      ],
      "metadata": {
        "id": "KBTdV-3Ukrsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grid_search(X_train, y_train, X_test, y_test):\n",
        "    best_accuracy,best_hyperparams,best_kernel = -1,None,None\n",
        "\n",
        "    # Define hyperparameters and kernels to search\n",
        "    # Cs = [0.1, 1.0, 10.0]\n",
        "    Cs = [3.0]\n",
        "    # kernels = [linear_kernel, polynomial_kernel, rbf_kernel]\n",
        "    kernels = [rbf_kernel]\n",
        "    for C in Cs:\n",
        "        for kernel in kernels:\n",
        "            # Train SVM model\n",
        "            support_vectors, support_vector_labels, alpha_sv, bias = train_svm(X_train, y_train, kernel, C)\n",
        "            print(\"Shape of Support Vectors \",support_vectors.shape)\n",
        "\n",
        "            # Predict using trained model\n",
        "            y_pred = predict_svm(X_test, support_vectors, support_vector_labels, alpha_sv, bias, kernel)\n",
        "\n",
        "            # Evaluate accuracy\n",
        "            accuracy = np.mean(y_pred == y_test)\n",
        "\n",
        "            # Check if this model is the best so far\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                best_hyperparams = {'C': C}\n",
        "                if kernel == linear_kernel:\n",
        "                    best_kernel = 'linear'\n",
        "                elif kernel == polynomial_kernel:\n",
        "                    best_kernel = 'polynomial'\n",
        "                else:\n",
        "                    best_kernel = 'rbf'\n",
        "\n",
        "    return {'hyperparameters': best_hyperparams, 'kernel': best_kernel, 'accuracy': best_accuracy}"
      ],
      "metadata": {
        "id": "GFis1eorkvUr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "# print(\"Shape of support_vectors:\", support_vectors.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBfQdR2gpRxT",
        "outputId": "803f795e-9727-4648-ae5b-acd5ffb2c5ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_test: (4200, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform Grid Search"
      ],
      "metadata": {
        "id": "MpDkZ6h7k2JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Print best hyperparameters and performance metrics\n",
        "print(\"Best Hyperparameters:\", best_model['hyperparameters'])\n",
        "print(\"Best Kernel:\", best_model['kernel'])\n",
        "print(\"Best Accuracy:\", best_model['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSF6bRqckv1Y",
        "outputId": "69bbe635-29df-4434-bf10-b17174b7aeb9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -3.4443e+03 -8.9639e+04  2e+05  8e-01  7e-15\n",
            " 1: -3.2089e+03 -3.1937e+04  3e+04  2e-02  4e-15\n",
            " 2: -4.4610e+03 -1.1951e+04  8e+03  4e-03  4e-15\n",
            " 3: -4.9717e+03 -6.6659e+03  2e+03  3e-04  4e-15\n",
            " 4: -5.1097e+03 -5.5569e+03  4e+02  2e-13  5e-15\n",
            " 5: -5.1445e+03 -5.2315e+03  9e+01  1e-13  5e-15\n",
            " 6: -5.1532e+03 -5.1618e+03  9e+00  1e-13  5e-15\n",
            " 7: -5.1542e+03 -5.1547e+03  4e-01  4e-14  5e-15\n",
            " 8: -5.1543e+03 -5.1543e+03  2e-02  2e-13  5e-15\n",
            " 9: -5.1543e+03 -5.1543e+03  4e-04  1e-13  5e-15\n",
            "Optimal solution found.\n",
            "[[6.76157564e-07]\n",
            " [3.41338519e-01]\n",
            " [9.63748487e-01]\n",
            " ...\n",
            " [7.48876192e-01]\n",
            " [2.63901519e-08]\n",
            " [2.99999997e+00]]\n",
            "[ True  True  True ...  True  True  True]\n",
            "Shape of Support Vectors  (9800, 10)\n",
            "-0.29283064893969446\n",
            "decision_function [-0.43767079  1.56442211 -0.82879573 ... -0.79193835 -0.52773403\n",
            "  0.14680877]\n",
            "[-1.  1. -1. ... -1. -1.  1.]\n",
            "Best Hyperparameters: {'C': 3.0}\n",
            "Best Kernel: rbf\n",
            "Best Accuracy: 0.7480952380952381\n"
          ]
        }
      ]
    }
  ]
}