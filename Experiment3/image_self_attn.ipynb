{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1SDVJmdSG2u"
      },
      "source": [
        "#Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "KM8P_crkSLjM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE7QjHemPhWp"
      },
      "source": [
        "#DATA LOADING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JW5N5eOPpMj",
        "outputId": "61a2922c-00a8-4f13-d689-f67ad087db01"
      },
      "outputs": [],
      "source": [
        "# ! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "Vi9roPabQn5A"
      },
      "outputs": [],
      "source": [
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjKrXu8HQt1e",
        "outputId": "18a9e44c-44aa-4ce4-86a5-c6aabee93f43"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d alessiocorrado99/animals10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-B4nRCqSUML",
        "outputId": "d5f73a19-0cb3-4a2a-f638-ba236002b092"
      },
      "outputs": [],
      "source": [
        "# zip_file_path = '/content/animals10.zip'\n",
        "\n",
        "# # Create a directory to extract the files\n",
        "# extract_dir = '/content/dataset'\n",
        "# os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# # Extract files from the ZIP archive\n",
        "# with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "#     for member in tqdm(zip_ref.infolist(), desc='Extracting files'):\n",
        "#         zip_ref.extract(member, extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "mMv4yTBgQzyK"
      },
      "outputs": [],
      "source": [
        "def load_dataset(directory, image_size=(128, 128)):\n",
        "    data = []\n",
        "    labels = []\n",
        "    label_mapping = {'cane': 0, 'cavallo': 1, 'elefante': 2, 'farfalla': 3, 'gallina': 4, 'gatto': 5, 'mucca': 6, 'pecora': 7, 'ragno': 8, 'scoiattolo': 9}\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in tqdm(files):\n",
        "            if file.endswith((\".jpg\", \".png\" ,\".jpeg\")):\n",
        "                image_path = os.path.join(root, file)\n",
        "                label = os.path.basename(os.path.normpath(root))\n",
        "                if label in label_mapping:\n",
        "                    image = Image.open(image_path).convert('RGB')\n",
        "                    image = image.resize(image_size)\n",
        "                    image = np.array(image)\n",
        "                    data.append(image)\n",
        "                    labels.append(label_mapping[label])\n",
        "\n",
        "    data = np.array(data)\n",
        "    labels = np.array(labels)\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fvc9x1nOHab",
        "outputId": "1087ad64-3d3b-474c-8712-74f0a9c086e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "  0%|          | 1/1668 [00:00<03:03,  9.07it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1668/1668 [00:15<00:00, 108.44it/s]\n",
            "100%|██████████| 3098/3098 [00:07<00:00, 430.76it/s]\n",
            "100%|██████████| 1862/1862 [00:03<00:00, 484.91it/s]\n",
            "100%|██████████| 1820/1820 [00:06<00:00, 263.28it/s]\n",
            "100%|██████████| 2623/2623 [00:08<00:00, 294.55it/s]\n",
            "100%|██████████| 2112/2112 [00:08<00:00, 262.82it/s]\n",
            "100%|██████████| 1866/1866 [00:03<00:00, 470.48it/s]\n",
            "100%|██████████| 1446/1446 [00:05<00:00, 274.26it/s]\n",
            "100%|██████████| 4821/4821 [00:13<00:00, 367.63it/s]\n",
            "100%|██████████| 4863/4863 [00:10<00:00, 466.61it/s]\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "data_dir = '/home/jyotishr/PRNN_ASS_3/Dataset/raw-img'\n",
        "data, labels = load_dataset(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set: (13097, 128, 128, 3) (13097,)\n",
            "Validation set: (2614, 128, 128, 3) (2614,)\n",
            "Test set: (10468, 128, 128, 3) (10468,)\n"
          ]
        }
      ],
      "source": [
        "def split(x, y, test_size=0.4, val_size=0.1, random_state=None):\n",
        "    # Find unique classes\n",
        "    classes = np.unique(y)\n",
        "    # Initialize arrays to hold indices for each class\n",
        "    class_indices = {c: np.where(y == c)[0] for c in classes}\n",
        "    \n",
        "    # Split each class's indices into train, validation, and test sets\n",
        "    train_indices = []\n",
        "    val_indices = []\n",
        "    test_indices = []\n",
        "    for c in classes:\n",
        "        indices = class_indices[c]\n",
        "        np.random.seed(random_state)\n",
        "        np.random.shuffle(indices)\n",
        "        test_count = int(len(indices) * test_size)\n",
        "        val_count = int(len(indices) * val_size)\n",
        "        \n",
        "        test_indices.extend(indices[:test_count])\n",
        "        val_indices.extend(indices[test_count:test_count + val_count])\n",
        "        train_indices.extend(indices[test_count + val_count:])\n",
        "    \n",
        "    # Shuffle the indices to mix the classes\n",
        "    np.random.seed(random_state)\n",
        "    np.random.shuffle(train_indices)\n",
        "    np.random.shuffle(val_indices)\n",
        "    np.random.shuffle(test_indices)\n",
        "    \n",
        "    # Use the indices to split the data\n",
        "    x_train, y_train = x[train_indices], y[train_indices]\n",
        "    x_val, y_val = x[val_indices], y[val_indices]\n",
        "    x_test, y_test = x[test_indices], y[test_indices]\n",
        "    \n",
        "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
        "\n",
        "# Splitting data\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = split(data, labels)\n",
        "\n",
        "# Printing the shapes of the datasets to verify the split\n",
        "print(\"Train set:\", x_train.shape, y_train.shape)\n",
        "print(\"Validation set:\", x_val.shape, y_val.shape)\n",
        "print(\"Test set:\", x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "id": "ne8H7a6JRq68",
        "outputId": "5fabfaf6-6df8-4131-f287-26ec92f0662e"
      },
      "outputs": [],
      "source": [
        "# # Shuffle the data and labels together\n",
        "# rng = np.random.RandomState(42)  # Set a (os, numpy, PIL, and tqdm) random seed for reproducibility\n",
        "# permutation = rng.permutation(len(data))\n",
        "# data = data[permutation]\n",
        "# labels = labels[permutation]\n",
        "\n",
        "# num_samples = len(data)\n",
        "# train_ratio = 0.6\n",
        "# val_ratio = 0.1\n",
        "# test_ratio = 0.3\n",
        "\n",
        "# # Calculate the sizes for each set\n",
        "# train_size = int(num_samples * train_ratio)\n",
        "# val_size = int(num_samples * val_ratio)\n",
        "# test_size = num_samples - train_size - val_size\n",
        "\n",
        "# # Split the data into train, validation, and test sets\n",
        "# x_train, x_val, x_test = data[:train_size], data[train_size:train_size+val_size], data[train_size+val_size:]\n",
        "# y_train, y_val, y_test = labels[:train_size], labels[train_size:train_size+val_size], labels[train_size+val_size:]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QpDfq38hksZY"
      },
      "outputs": [],
      "source": [
        "# x_train = (x_train / 255.0) - 0.5\n",
        "# x_val = (x_val / 255.0) - 0.5\n",
        "# x_test = (x_test / 255.0) - 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1joPF4yMv82"
      },
      "source": [
        "#NEURAL NETWORK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "l4IflFi4MzWe"
      },
      "outputs": [],
      "source": [
        "class Neural_Network:\n",
        "\n",
        "    def __init__(self, Network):\n",
        "        self.Network = Network\n",
        "\n",
        "    # forward pass\n",
        "    def forward_pass(self, X):\n",
        "        n = X\n",
        "        for i in self.Network:\n",
        "            n = i.forward_pass(n,saved_weights = None)\n",
        "        return n\n",
        "\n",
        "    #backward pass\n",
        "    def backprop(self, Y):\n",
        "        m = Y\n",
        "        for i in (reversed(self.Network)):\n",
        "            m = i.backprop(m)\n",
        "\n",
        "    # applying sgd\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        for i in self.Network:\n",
        "            i.applying_sgd(batch_size = batch_size)\n",
        "\n",
        "    # applying adam\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        for i in self.Network:\n",
        "            i.applying_adam(batch_size)\n",
        "\n",
        "    # changing alpha\n",
        "    def change_alpha(self):\n",
        "        for i in self.Network:\n",
        "            i.change_alpha()\n",
        "\n",
        "    # saving weights\n",
        "    def saving_params(self):\n",
        "        for i,layer in enumerate(self.Network):\n",
        "            layer.saving_params()\n",
        "\n",
        "    # predicting after loading weights\n",
        "    def predict(self,X):\n",
        "        n = X\n",
        "        for i in self.Network:\n",
        "            n = i.forward_pass(n,saved_weights = 1)\n",
        "        return n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcV66ahvWeCg"
      },
      "source": [
        "#ADAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "xVVFC4ghWfjt"
      },
      "outputs": [],
      "source": [
        "class Adam:\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.epsilon = epsilon\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        self.t = 0\n",
        "\n",
        "    def update(self, grads):\n",
        "        if self.m is None:\n",
        "            self.m = np.zeros_like(grads)\n",
        "            self.v = np.zeros_like(grads)\n",
        "\n",
        "        self.t += 1\n",
        "        self.m = self.beta1 * self.m + (1 - self.beta1) * grads\n",
        "        self.v = self.beta2 * self.v + (1 - self.beta2) * (grads ** 2)\n",
        "        m_hat = self.m / (1 - self.beta1 ** self.t)\n",
        "        v_hat = self.v / (1 - self.beta2 ** self.t)\n",
        "        return self.lr * m_hat / (np.sqrt(v_hat) + self.epsilon)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICFprSpThcEZ"
      },
      "source": [
        "#ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "grUp4qNxhfGF"
      },
      "outputs": [],
      "source": [
        "class accuracy:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def value(self, out, Y):\n",
        "        return np.mean(self.out == Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u36GTfzYMoie"
      },
      "source": [
        "#SOFTMAX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "d1UaayUcMbEj"
      },
      "outputs": [],
      "source": [
        "class softmax:\n",
        "\n",
        "    def __init__(self,n_classes):\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "    # def expansion(self, actual_pred):\n",
        "    #     print(actual_pred.shape)\n",
        "    #     d = actual_pred.shape[0]\n",
        "    #     one_hot_pred = np.zeros((d,self.n_classes))\n",
        "    #     for i in range(0,d):\n",
        "    #         one_hot_pred[i,actual_pred[i]] = 1\n",
        "    #     return one_hot_pred\n",
        "\n",
        "    def expansion(self, actual_pred):\n",
        "        # print(actual_pred.shape)\n",
        "        # d = actual_pred.shape[0]\n",
        "        one_hot_pred = np.zeros(self.n_classes)\n",
        "        one_hot_pred[actual_pred] = 1\n",
        "        return one_hot_pred\n",
        "\n",
        "    def forward_pass(self, z, saved_weights = None):\n",
        "\n",
        "        # # vectorised form below\n",
        "        # shiftx = z - np.max(z, axis=1, keepdims=True)\n",
        "\n",
        "        # # Exponentiate the shifted values\n",
        "        # exps = np.exp(shiftx)\n",
        "\n",
        "        # # Calculate softmax probabilities\n",
        "        # self.softmax_probs = exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "        # return self.softmax_probs\n",
        "\n",
        "\n",
        "        # vectorised form below\n",
        "        shiftx = z - np.max(z, axis=0, keepdims=True)\n",
        "\n",
        "        # Exponentiate the shifted values\n",
        "        exps = np.exp(shiftx)\n",
        "\n",
        "        # Calculate softmax probabilities\n",
        "        self.softmax_probs = exps / np.sum(exps, axis=0, keepdims=True)\n",
        "\n",
        "        return self.softmax_probs\n",
        "\n",
        "    def backprop(self, Y):\n",
        "        y = self.expansion(Y)\n",
        "        self.grad = (self.softmax_probs - y)\n",
        "        return self.grad\n",
        "\n",
        "\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def change_alpha(self):\n",
        "        pass\n",
        "\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def saving_params(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFA4x5xluYu-"
      },
      "source": [
        "#FLATTEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "V7xVcXYTyn7Q"
      },
      "outputs": [],
      "source": [
        "class reshape:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward_pass(self, data, saved_weights = None):\n",
        "        self.data_shape = data.shape\n",
        "\n",
        "        self.flatten = data.flatten()\n",
        "        return self.flatten\n",
        "\n",
        "    def backprop(self, prev_data):\n",
        "        return prev_data.reshape(self.data_shape)\n",
        "\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def change_alpha(self):\n",
        "        pass\n",
        "\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def saving_params(self):\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY1FXpehudTa"
      },
      "source": [
        "#CROSS ENTROPY\n",
        "\n",
        "L = - sum ( y_i * log(p_i) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "TPEO8GE_H_L6"
      },
      "outputs": [],
      "source": [
        "class cross_entropy:\n",
        "\n",
        "    def _init_(self):\n",
        "        pass\n",
        "\n",
        "    def loss(self, A, Y):\n",
        "\n",
        "        # Compute cross-entropy loss\n",
        "        ce_loss = - np.log(A[Y])\n",
        "\n",
        "        return ce_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "C6AYYJwNu11u"
      },
      "outputs": [],
      "source": [
        "\n",
        "class relu:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def forward_pass(self, z, saved_weights = None):\n",
        "        self.z = z\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "    def derivative(self, a):\n",
        "        return np.where(a > 0, 1, 0)\n",
        "\n",
        "    def backprop(self, grad_previous):\n",
        "        return grad_previous * self.derivative(self.z)\n",
        "\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def change_alpha(self):\n",
        "        pass\n",
        "\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def saving_params(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZdGEebSNvct"
      },
      "source": [
        "#LEAKY RELU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "IVE4zHVqNyfD"
      },
      "outputs": [],
      "source": [
        "class LeakyReLU:\n",
        "    def __init__(self, alpha=0.01):\n",
        "        self.alpha = alpha\n",
        "        self.z = None\n",
        "\n",
        "    def forward_pass(self, z, saved_weights = None):\n",
        "        self.z = z\n",
        "        return np.where(z > 0, z, self.alpha * z)\n",
        "\n",
        "    def derivative(self, a):\n",
        "        return np.where(a > 0, 1, self.alpha)\n",
        "\n",
        "    def backprop(self, grad_previous):\n",
        "        return grad_previous * self.derivative(self.z)\n",
        "\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def change_alpha(self):\n",
        "        pass\n",
        "\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        pass\n",
        "\n",
        "    def saving_params(self):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0Of4rUqNSQr"
      },
      "source": [
        "#LAYER_MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 335,
      "metadata": {
        "id": "r9qAbtbZNVEj"
      },
      "outputs": [],
      "source": [
        "class Linear_Layer:\n",
        "\n",
        "    def __init__(self, in_dim, out_dim, alpha = 0.01,index = 0,reg = None, reg_penelty = 0):\n",
        "        self.theta = np.random.randn(in_dim, out_dim)/(in_dim * out_dim)\n",
        "        self.grad_theta = np.zeros_like(self.theta)\n",
        "        self.bias = np.ones((out_dim,))/out_dim\n",
        "        self.grad_bias = np.zeros_like(self.bias)\n",
        "        self.optimizer_theta = Adam(lr = alpha)\n",
        "        self.optimizer_bias = Adam(lr = alpha)\n",
        "        self.alpha = alpha\n",
        "        # self.index = index\n",
        "        self.reg = reg\n",
        "        self.reg_penelty = reg_penelty\n",
        "\n",
        "\n",
        "    def forward_pass(self, X, saved_weights = None):\n",
        "        if saved_weights != None:\n",
        "          saved_data = np.load(f'/content/drive/MyDrive/Colab Notebooks/Saved_Models/Linear_layer{self.index}.npz')\n",
        "          self.theta =  saved_data['arr1']\n",
        "          self.bias = saved_data['arr2']\n",
        "\n",
        "        self.X = X\n",
        "        self.z = np.dot(X,self.theta) + self.bias\n",
        "        return self.z\n",
        "\n",
        "\n",
        "    def backprop(self, grad_previous):\n",
        "        t= self.X.shape[0]\n",
        "        self.grad_theta = np.dot(self.X.reshape(-1, 1), grad_previous.reshape(1,-1))\n",
        "        self.grad_bias = (grad_previous.sum(axis=0))/t\n",
        "        self.grad_back = np.dot(grad_previous, self.theta.transpose()) \n",
        "        # print(f\"LLL : {self.grad_back[0]}\")\n",
        "\n",
        "        # d_l_d_inputs = np.dot(d_l_d_out, self.weights.T)\n",
        "        # d_l_d_weights = np.dot(self.last_input.reshape(-1, 1), d_l_d_outd_l_d_inputs = np.dot(d_l_d_out, self.weights.T)\n",
        "        # d_l_d_weights = np.dot(self.last_input.reshape(-1, 1), d_l_d_out.reshape(1, -1))\n",
        "        # d_l_d_biases = d_l_d_out)\n",
        "        # d_l_d_biases = d_l_d_out\n",
        "\n",
        "        # Add L1 and L2 and elastic regularization terms\n",
        "        # if self.reg == 'l1':\n",
        "        #   self.grad_theta += self.reg_penelty * np.sign(self.theta)\n",
        "        #   self.grad_bias += self.reg_penelty * np.sign(self.bias)\n",
        "\n",
        "        # elif self.reg == 'l2':\n",
        "        #   self.grad_theta += 2 * self.reg_penelty * self.theta\n",
        "        #   self.grad_bias += 2 * self.reg_penelty * self.bias\n",
        "\n",
        "        # elif self.reg == 'elastic':\n",
        "        #   self.grad_theta += self.reg_penelty * (0.5 * np.sign(self.theta) + 0.5 * self.theta)\n",
        "        #   self.grad_bias += self.reg_penelty * (0.5 * np.sign(self.bias) + 0.5 * self.bias)\n",
        "\n",
        "        return self.grad_back\n",
        "\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        self.theta = self.theta - (self.alpha*self.grad_theta / batch_size)\n",
        "        self.bias = self.bias - (self.alpha*self.grad_bias / batch_size)\n",
        "        \n",
        "        # self.grad_theta = np.zeros_like(self.grad_theta)\n",
        "        # self.grad_bias = np.zeros_like(self.grad_bias)\n",
        "\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        self.theta -= self.optimizer_theta.update(self.grad_theta/ batch_size)\n",
        "        self.bias -= self.optimizer_bias.update(self.grad_bias/ batch_size)\n",
        "        \n",
        "        self.grad_theta = np.zeros_like(self.grad_theta)\n",
        "        self.grad_bias = np.zeros_like(self.grad_bias)\n",
        "\n",
        "    def change_alpha(self):\n",
        "        self.alpha = self.alpha/5\n",
        "\n",
        "    def saving_params(self):\n",
        "        np.savez(f'/content/drive/MyDrive/Colab Notebooks/Saved_Models/Linear_layer{self.index}.npz',arr1 = self.Theta, arr2 = self.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF6snHrpVMPG"
      },
      "source": [
        "#SELF ATTENTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 332,
      "metadata": {
        "id": "MO7-lsPyVLow"
      },
      "outputs": [],
      "source": [
        "class self_attention:\n",
        "    def __init__(self, d, d_k, alpha = 0.01,index = 0,reg = None, reg_penelty = 0):\n",
        "        self.d_k = d_k\n",
        "        self.W_K = np.random.randn(d, d_k)/(d * d_k)\n",
        "        self.W_Q = np.random.randn(d, d_k)/(d * d_k)\n",
        "        self.W_V = np.random.randn(d, d_k)/(d * d_k)\n",
        "        \n",
        "        self.grad_Wk = np.zeros_like(self.W_K)\n",
        "        self.grad_Wq = np.zeros_like(self.W_Q)\n",
        "        self.grad_Wv = np.zeros_like(self.W_V)\n",
        "\n",
        "        self.optimizer_Wk = Adam(lr = alpha)\n",
        "        self.optimizer_Wv = Adam(lr = alpha)\n",
        "        self.optimizer_Wq = Adam(lr = alpha)\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # self.optimizer_bias = Adam(lr = alpha)\n",
        "        # self.alpha = alpha\n",
        "        # self.reg = reg\n",
        "        # self.reg_penelty = reg_penelty\n",
        "\n",
        "    def softmax(self,z):\n",
        "        # self.n = z.shape[1]\n",
        "        # vectorised form below\n",
        "        shiftx = z - np.max(z, axis=1, keepdims=True)\n",
        "\n",
        "        # Exponentiate the shifted values\n",
        "        exps = np.exp(shiftx)\n",
        "\n",
        "        # Calculate softmax probabilities\n",
        "        softmax_probs = exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "        return softmax_probs\n",
        "\n",
        "\n",
        "    def forward_pass(self, X, saved_weights = None):\n",
        "        # if saved_weights != None:\n",
        "        #   saved_data = np.load(f'/content/drive/MyDrive/Colab Notebooks/Saved_Models/Linear_layer{self.index}.npz')\n",
        "        #   self.W_K =  saved_data['arr1']\n",
        "        #   self.W_Q =  saved_data['arr2']\n",
        "        #   self.W_V =  saved_data['arr3']\n",
        "\n",
        "        self.X = X\n",
        "\n",
        "        # query key value vectors\n",
        "        self.Q = np.matmul(X, self.W_Q)\n",
        "        self.K = np.matmul(X, self.W_K)\n",
        "        self.V = np.matmul(X, self.W_V)\n",
        "\n",
        "        # print(self.W_K[0][0])\n",
        "        t = np.matmul(self.Q, (self.K).T) / np.sqrt(self.d_k)\n",
        "        self.H = self.softmax(t)\n",
        "        output = np.matmul(self.H,self.V)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def backprop(self, grad_previous):\n",
        "\n",
        "        self.grad_Wv = np.matmul(np.matmul(self.X.T,self.H.T),grad_previous)\n",
        "\n",
        "        t1 = np.multiply(self.H,np.matmul(grad_previous,self.V.T))\n",
        "        t2 = self.Q - np.matmul(self.H,self.Q)\n",
        "        self.grad_Wk = (1/np.sqrt(self.d_k)) * np.matmul(np.matmul(self.X.T,t1),t2)\n",
        "\n",
        "        t3 = np.sum(np.multiply(self.H,np.matmul(grad_previous,self.V.T)),axis = 1)\n",
        "        t4 = np.multiply(t3,self.H)\n",
        "        t5 = np.multiply(self.H, np.matmul(grad_previous,self.V.T)) - t4\n",
        "        self.grad_Wq = (1/np.sqrt(self.d_k)) * np.matmul(np.matmul(self.X.T,t5),self.K)\n",
        "\n",
        "\n",
        "        # Add L1 and L2 and elastic regularization terms\n",
        "        # if self.reg == 'l1':\n",
        "        #   self.grad_theta += self.reg_penelty * np.sign(self.Theta)\n",
        "        #   self.grad_bias += self.reg_penelty * np.sign(self.bias)\n",
        "        #   self.grad_theta += self.reg_penelty * np.sign(self.Theta)\n",
        "\n",
        "        # elif self.reg == 'l2':\n",
        "        #   self.grad_theta += 2 * self.reg_penelty * self.Theta\n",
        "        #   self.grad_bias += 2 * self.reg_penelty * self.bias\n",
        "        #   self.grad_theta += self.reg_penelty * np.sign(self.Theta)\n",
        "\n",
        "        # elif self.reg == 'elastic':\n",
        "        #   self.grad_theta += self.reg_penelty * (0.5 * np.sign(self.Theta) + 0.5 * self.Theta)\n",
        "        #   self.grad_bias += self.reg_penelty * (0.5 * np.sign(self.bias) + 0.5 * self.bias)\n",
        "        #   self.grad_theta += self.reg_penelty * np.sign(self.Theta)\n",
        "\n",
        "        return 0\n",
        "\n",
        "    def applying_sgd(self,batch_size = 1):\n",
        "        # print(self.grad_Wk[0][0])\n",
        "        # print(self.W_K[0][0])\n",
        "        self.W_K -=  self.alpha * self.grad_Wk / batch_size\n",
        "        # print(self.W_K[0][0])\n",
        "        self.W_Q -=  self.alpha * self.grad_Wq / batch_size\n",
        "        self.W_V -=  self.alpha * self.grad_Wv / batch_size\n",
        "        \n",
        "        # self.grad_Wk =  np.zeros_like(self.grad_Wk)\n",
        "        # self.grad_Wq =  np.zeros_like(self.grad_Wq)\n",
        "        # self.grad_Wv =  np.zeros_like(self.grad_Wv)\n",
        "\n",
        "    def applying_adam(self,batch_size = 1):\n",
        "        self.W_K =  self.optimizer_Wk.update(self.grad_Wk / batch_size)        \n",
        "        self.W_Q =  self.optimizer_Wq.update(self.grad_Wq / batch_size)\n",
        "        self.W_V =  self.optimizer_Wv.update(self.grad_Wv / batch_size)\n",
        "        \n",
        "        self.grad_Wk =  np.zeros_like(self.grad_Wk)\n",
        "        self.grad_Wq =  np.zeros_like(self.grad_Wq)\n",
        "        self.grad_Wv =  np.zeros_like(self.grad_Wv)\n",
        "\n",
        "\n",
        "    def change_alpha(self):\n",
        "        self.alpha = self.alpha/5\n",
        "\n",
        "    def saving_params(self):\n",
        "        np.savez(f'/content/drive/MyDrive/Colab Notebooks/Saved_Models/Linear_layer{self.index}.npz',arr1 = self.Theta, arr2 = self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "GTlMSt7ChaJZ"
      },
      "outputs": [],
      "source": [
        "# Implementing Image Tokenisation:\n",
        "def image_tokenization(images, patch_size):\n",
        "    num_images, image_height, image_width, channels = images.shape\n",
        "\n",
        "    # Initialize an array to store the flattened patches\n",
        "    patches_dataset = []\n",
        "\n",
        "    # Extract patches for each image\n",
        "    for i in range(num_images):\n",
        "        image = images[i]\n",
        "        patches_image = []\n",
        "        for h in range(0, image_height-patch_size+1, patch_size):\n",
        "            for w in range(0, image_width-patch_size+1, patch_size):\n",
        "                # Define patch\n",
        "                patch = image[h:h+patch_size, w:w+patch_size, :].copy().reshape(-1)\n",
        "                patches_image.append(patch)\n",
        "\n",
        "        patches_dataset.append(patches_image)\n",
        "    return np.array(patches_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def positional_encoding(data):\n",
        "    n_images, n_patches, n_features = data.shape\n",
        "\n",
        "    position = np.arange(n_features)\n",
        "    freqs = 1 / (10000 ** (2 * np.arange(n_features) / n_features))\n",
        "\n",
        "    sin_encoding = np.sin(position[:n_features // 2] * freqs[:n_features // 2])\n",
        "    cos_encoding = np.cos(position[n_features // 2:] * freqs[n_features // 2:])\n",
        "\n",
        "    encoding = np.concatenate([sin_encoding, cos_encoding], axis=0)\n",
        "\n",
        "    # Expand dimensions of encoding to match data shape\n",
        "    encoding = np.expand_dims(encoding, axis=(0, 1))\n",
        "\n",
        "    # Add encoding to data using broadcasting\n",
        "    encoded_data = data + encoding\n",
        "\n",
        "    return encoded_data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def PCA(X, n_components):\n",
        "    # Standardize the data\n",
        "    X_std = (X - np.mean(X, axis=0)) #/ np.std(X, axis=0)\n",
        "    \n",
        "    # Compute the covariance matrix efficiently\n",
        "    cov_matrix = np.cov(X_std, rowvar=False)\n",
        "    \n",
        "    # Compute the eigenvalues and eigenvectors\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "    \n",
        "    # Sort eigenvectors based on eigenvalues\n",
        "    idx = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvectors = eigenvectors[:, idx]\n",
        "    \n",
        "    # Choose the top n_components eigenvectors\n",
        "    top_eigenvectors = eigenvectors[:, :n_components]\n",
        "\n",
        "    # Project data onto the selected eigenvectors\n",
        "    transformed_data = np.dot(X_std, top_eigenvectors)\n",
        "    \n",
        "    return transformed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "x_val = x_val / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_pca_success\n",
            "test_pca_success\n",
            "val_pca_success\n",
            "PCA train shape: (13097, 64, 100)\n",
            "PCA test shape: (10468, 64, 100)\n",
            "PCA val shape: (1000, 64, 100)\n"
          ]
        }
      ],
      "source": [
        "n_component = 100\n",
        "limit = 1000\n",
        "\n",
        "x_train_flat = image_tokenization(x_train,16)\n",
        "x_test_flat = image_tokenization(x_test,16)\n",
        "x_val_flat = image_tokenization(x_val[:limit],16)\n",
        "\n",
        "\n",
        "x_train_pca = np.zeros((x_train_flat.shape[0],x_train_flat.shape[1],n_component))\n",
        "x_test_pca  = np.zeros((x_test_flat.shape[0] ,x_test_flat.shape[1],n_component))\n",
        "x_val_pca   = np.zeros((x_val_flat.shape[0]  ,x_val_flat.shape[1],n_component))\n",
        "\n",
        "for i,img in enumerate(x_train_flat):\n",
        "    x_train_pca[i] = PCA(X = img,n_components = n_component)\n",
        "    \n",
        "print(\"train_pca_success\")\n",
        "    \n",
        "for i,img in enumerate(x_test_flat):\n",
        "    x_test_pca[i] = PCA(X = img,n_components = n_component)\n",
        "\n",
        "print(\"test_pca_success\")\n",
        "\n",
        "    \n",
        "for i,img in enumerate(x_val_flat):\n",
        "    x_val_pca[i] = PCA(X = img,n_components = n_component)\n",
        "\n",
        "print(\"val_pca_success\")\n",
        "\n",
        "\n",
        "\n",
        "print(f\"PCA train shape: {x_train_pca.shape}\")\n",
        "print(f\"PCA test shape: {x_test_pca.shape}\")\n",
        "print(f\"PCA val shape: {x_val_pca.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded train shape: (13097, 64, 100)\n",
            "Encoded test shape: (10468, 64, 100)\n",
            "Encoded validation shape: (1000, 64, 100)\n"
          ]
        }
      ],
      "source": [
        "x_train_encoded = positional_encoding(x_train_pca)\n",
        "print(f\"Encoded train shape: {x_train_encoded.shape}\")\n",
        "\n",
        "x_test_encoded = positional_encoding(x_test_pca)\n",
        "print(f\"Encoded test shape: {x_test_encoded.shape}\")\n",
        "\n",
        "x_val_encoded = positional_encoding(x_val_pca)\n",
        "print(f\"Encoded validation shape: {x_val_encoded.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 336,
      "metadata": {},
      "outputs": [],
      "source": [
        "complete_NN = Neural_Network([\n",
        "    self_attention(d = n_component,d_k = 64, alpha = 0.1),\n",
        "    reshape(),\n",
        "    Linear_Layer(4096,784, alpha = 0.1),\n",
        "    LeakyReLU(),\n",
        "    Linear_Layer(784,256, alpha = 0.1),\n",
        "    LeakyReLU(),\n",
        "    Linear_Layer(256,64, alpha = 0.1),\n",
        "    LeakyReLU(),\n",
        "    Linear_Layer(64,10, alpha = 0.1),\n",
        "    LeakyReLU(),\n",
        "    softmax(10)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH 1 \t Train Accuracy is : 18.299839657936932\n",
            "EPOCH 2 \t Train Accuracy is : 18.326614931626448\n",
            "EPOCH 3 \t Train Accuracy is : 18.401783612062257\n",
            "EPOCH 4 \t Train Accuracy is : 18.46382859547044\n",
            "EPOCH 5 \t Train Accuracy is : 18.481942574931242\n"
          ]
        }
      ],
      "source": [
        "ce = cross_entropy()\n",
        "epochs = 5\n",
        "batch = 1\n",
        "\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "\n",
        "for e in range(epochs):\n",
        "  loss = 0\n",
        "  predictions = []\n",
        "  for i,img in enumerate(x_train_encoded[:]):\n",
        "    probs = complete_NN.forward_pass(img)\n",
        "    predictions.append(np.argmax(probs))\n",
        "    loss += ce.loss(probs,y_train[i])\n",
        "    complete_NN.backprop(y_train[i])\n",
        "    \n",
        "    # if (i+1) % batch == 0 or (i+1) == x_train_encoded.shape[0]:\n",
        "    complete_NN.applying_sgd(batch)\n",
        "\n",
        "  print(f\"EPOCH {e+1} \\t Train Accuracy is : {np.mean(predictions == y_train[:x_train_encoded[:].shape[0]])*100}\")\n",
        "  # print(f\"Loss is : {loss / x_train_encoded.shape[0]}\")\n",
        "  \n",
        "  train_preds = []\n",
        "  val_preds = []\n",
        "  t_loss = 0\n",
        "  v_loss = 0\n",
        "  \n",
        "  \n",
        "  \n",
        "  for i in range(limit):\n",
        "    train_probs = complete_NN.forward_pass(x_train_encoded[i])\n",
        "    val_probs = complete_NN.forward_pass(x_val_encoded[i])\n",
        "    \n",
        "    train_preds.append(np.argmax(train_probs))\n",
        "    t_loss += ce.loss(train_probs,y_train[i])\n",
        "    \n",
        "    val_preds.append(np.argmax(val_probs))\n",
        "    v_loss += ce.loss(val_probs,y_val[i])\n",
        "    \n",
        "  train_loss.append(t_loss/limit)\n",
        "  val_loss.append(v_loss/limit)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs_list = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(epochs_list, train_loss, 'b', label='Train Loss')\n",
        "plt.plot(epochs_list, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "NYz11wDIZBiy",
        "outputId": "9df90a15-08cc-4670-a43e-49bb68357201"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy is : 18.58043561329767\n"
          ]
        }
      ],
      "source": [
        "test_predictions = []\n",
        "for i in x_test_encoded:\n",
        "    test_probs = complete_NN.forward_pass(i)\n",
        "    test_predictions.append(np.argmax(test_probs))\n",
        "\n",
        "print(f\"Test Accuracy is : {np.mean(test_predictions == y_test)*100}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 355,
      "metadata": {},
      "outputs": [],
      "source": [
        "def confusion_matrix(predicted,actual,n_classes):\n",
        "  conf_mat = np.zeros((n_classes, n_classes))\n",
        "  for i in range(len(predicted)):\n",
        "    conf_mat[int(actual[i])][int(predicted[i])] = conf_mat[int(actual[i])][int(predicted[i])] + 1\n",
        "\n",
        "  return conf_mat"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
