{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7G5OZOxCzFfn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLXv_h9nY1xm",
        "outputId": "e580b3b0-e3ed-4da5-e2be-bf7451f7648b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "class RandomForest:\n",
        "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n_samples, n_features = X_train.shape\n",
        "        for _ in range(self.n_estimators):\n",
        "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "            # Randomly select samples with replacement\n",
        "            sample_indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
        "            X_sampled = X_train[sample_indices]\n",
        "            y_sampled = y_train[sample_indices]\n",
        "            tree.fit(X_sampled, y_sampled)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = np.zeros(X_test.shape[0])\n",
        "        for tree in self.trees:\n",
        "            predictions += tree.predict(X_test)\n",
        "        return np.sign(predictions).astype(int)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yfh1Y2FeafNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.split_feature = None\n",
        "        self.split_threshold = None\n",
        "        self.left_child = None\n",
        "        self.right_child = None\n",
        "        self.prediction = None\n",
        "\n",
        "    def fit(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        if depth == self.max_depth or n_samples < self.min_samples_split or np.all(y == y[0]):\n",
        "            self.prediction = np.mean(y)\n",
        "            return\n",
        "\n",
        "        best_gain = 0\n",
        "        for feature_index in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = X[:, feature_index] < threshold\n",
        "                right_indices = ~left_indices\n",
        "                if np.sum(left_indices) == 0 or np.sum(right_indices) == 0:\n",
        "                    continue\n",
        "                gain = self._information_gain(y, y[left_indices], y[right_indices])\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain\n",
        "                    self.split_feature = feature_index\n",
        "                    self.split_threshold = threshold\n",
        "                    self.left_indices = left_indices\n",
        "                    self.right_indices = right_indices\n",
        "\n",
        "        if best_gain == 0:\n",
        "            self.prediction = np.mean(y)\n",
        "            return\n",
        "\n",
        "        self.left_child = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "        self.left_child.fit(X[self.left_indices], y[self.left_indices], depth+1)\n",
        "        self.right_child = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "        self.right_child.fit(X[self.right_indices], y[self.right_indices], depth+1)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / len(y)\n",
        "        return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "    def _information_gain(self, y, y_left, y_right):\n",
        "        p = len(y_left) / len(y)\n",
        "        return self._entropy(y) - p * self._entropy(y_left) - (1 - p) * self._entropy(y_right)\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.prediction is not None:\n",
        "            return np.ones(X.shape[0]) * self.prediction\n",
        "        else:\n",
        "            predictions = np.zeros(X.shape[0])\n",
        "            left_indices = X[:, self.split_feature] < self.split_threshold\n",
        "            predictions[left_indices] = self.left_child.predict(X[left_indices])\n",
        "            predictions[~left_indices] = self.right_child.predict(X[~left_indices])\n",
        "            return predictions"
      ],
      "metadata": {
        "id": "rGNyzHklbA5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GradientBoostedTree:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n_samples = X_train.shape[0]\n",
        "        # Initialize the prediction with the mean of the target values\n",
        "        pred = np.mean(y_train) * np.ones(n_samples)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Calculate the residuals\n",
        "            residuals = y_train - pred\n",
        "            # Fit a decision tree to the residuals\n",
        "            tree = DecisionTree(max_depth=self.max_depth)\n",
        "            tree.fit(X_train, residuals)\n",
        "            # Update the prediction using the tree and learning rate\n",
        "            pred += self.learning_rate * tree.predict(X_train)\n",
        "            # Save the tree\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        n_samples = X_test.shape[0]\n",
        "        # Initialize predictions with zeros\n",
        "        pred = np.zeros(n_samples)\n",
        "        # Make predictions using each tree and weight them\n",
        "        for tree in self.trees:\n",
        "            pred += tree.predict(X_test)\n",
        "        # Apply sign function to get the final predictions\n",
        "        return np.sign(pred).astype(int)"
      ],
      "metadata": {
        "id": "jT9Ee0HIbIfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Animal dataset\n",
        "path='/content/drive/MyDrive/PRNN/Assign_3/animal/animals10_data.npz'\n",
        "data = np.load(path)\n",
        "\n",
        "# Load the data from the .npz file\n",
        "image_data = np.load(path)\n",
        "image_data=image_data['data']\n",
        "# Extract images and labels\n",
        "labels = data['labels']"
      ],
      "metadata": {
        "id": "xE0rv0FLbLlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sizes for training, validation, and testing sets\n",
        "train_size = int(0.1 * len(image_data))\n",
        "val_size = int(0.85 * len(image_data))\n",
        "test_size = len(image_data) - train_size - val_size\n",
        "\n",
        "# Shuffle the data\n",
        "indices = np.random.permutation(len(image_data))\n",
        "image_data_shuffled = image_data[indices]\n",
        "labels_shuffled = labels[indices]\n",
        "\n",
        "# Split the data into training, validation, and testing sets\n",
        "x_train = image_data_shuffled[:train_size]\n",
        "y_train = labels_shuffled[:train_size]\n",
        "\n",
        "x_val = image_data_shuffled[train_size:train_size+val_size]\n",
        "y_val = labels_shuffled[train_size:train_size+val_size]\n",
        "\n",
        "x_test = image_data_shuffled[train_size+val_size:]\n",
        "y_test = labels_shuffled[train_size+val_size:]\n",
        "\n",
        "# Print the shapes of the split sets\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of x_val:\", x_val.shape)\n",
        "print(\"Shape of y_val:\", y_val.shape)\n",
        "print(\"Shape of x_test:\", x_test.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_UuFPnochYb",
        "outputId": "c26ccd14-81b5-4aed-8b77-d01f0aaeccae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (2617, 4096)\n",
            "Shape of y_train: (2617,)\n",
            "Shape of x_val: (22252, 4096)\n",
            "Shape of y_val: (22252,)\n",
            "Shape of x_test: (1310, 4096)\n",
            "Shape of y_test: (1310,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available, using CPU\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoOv2kdqc5NH",
        "outputId": "724e08bc-f924-4295-e944-b52a7c470f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is not available, using CPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForest(n_estimators=100)\n",
        "rf.fit(x_train, y_train)\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "\n",
        "# Gradient Boosted Tree\n",
        "gbt = GradientBoostedTree(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "gbt.fit(x_train, y_train)\n",
        "y_pred_gbt = gbt.predict(x_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy_rf = np.mean(y_pred_rf == y_test)\n",
        "accuracy_gbt = np.mean(y_pred_gbt == y_test)\n",
        "\n",
        "print(\"Random Forest Accuracy:\", accuracy_rf)\n",
        "print(\"Gradient Boosted Tree Accuracy:\", accuracy_gbt)"
      ],
      "metadata": {
        "id": "3zw1kriLbL2-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}